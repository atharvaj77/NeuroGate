apiVersion: v1
kind: ConfigMap
metadata:
  name: neurogate-config
  namespace: neurogate
  labels:
    app: neurogate
data:
  application-prod.yml: |
    server:
      port: 8080
      shutdown: graceful
      tomcat:
        threads:
          max: 500
          min-spare: 50
        max-connections: 20000
        accept-count: 200

    spring:
      application:
        name: neurogate

      ai:
        openai:
          base-url: https://api.openai.com
          chat:
            options:
              model: gpt-3.5-turbo
              temperature: 0.7
              max-tokens: 1000

      data:
        redis:
          host: redis-service
          port: 6379
          timeout: 3000ms
          jedis:
            pool:
              max-active: 100
              max-idle: 50
              min-idle: 10
              max-wait: 2000ms

    neurogate:
      qdrant:
        host: qdrant-service
        grpc-port: 6334
        rest-port: 6333
        collection-name: prompt_cache
        vector-size: 384
        similarity-threshold: 0.92
        timeout-seconds: 10

      router:
        complexity-threshold: 50
        enable-local-routing: false
        enable-semantic-cache: true
        cache-ttl-hours: 48

      rate-limit:
        enabled: true
        default-rpm: 5000
        burst-capacity: 500
        refill-tokens-per-minute: 5000

    management:
      endpoints:
        web:
          exposure:
            include: health,info,metrics,prometheus
          base-path: /actuator
      endpoint:
        health:
          show-details: when-authorized
          probes:
            enabled: true
      metrics:
        export:
          prometheus:
            enabled: true
        distribution:
          percentiles-histogram:
            http.server.requests: true

    logging:
      level:
        root: INFO
        com.neurogate: INFO
        org.springframework.ai: WARN
        io.qdrant: WARN
      pattern:
        console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
